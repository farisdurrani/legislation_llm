{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir_path: list) -> dict:\n",
    "    files = [file for file in os.listdir(dir_path)]\n",
    "    file_paths = [dir_path + file for file in files]\n",
    "    return pd.DataFrame({\"file_name\": files, \"file_path\": file_paths})\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def get_text(db: pd.DataFrame) -> pd.DataFrame:\n",
    "    db[\"text\"] = db[\"file_path\"].apply(read_file)\n",
    "    return db\n",
    "\n",
    "\n",
    "# def get_context(db: pd.DataFrame, overlap: int = 300) -> pd.DataFrame:\n",
    "#     context = []\n",
    "#     for row in db.iterrows():\n",
    "#         i = row[\"chunk\"].metadata[\"start_index\"]\n",
    "#         if i - overlap < 0 or i + overlap > len(row[\"text\"]):\n",
    "#             continue\n",
    "\n",
    "#         context.append(row[\"text\"][i - overlap : i + overlap])\n",
    "\n",
    "#     db[\"context\"] = context\n",
    "#     return db\n",
    "\n",
    "\n",
    "def get_context_for_row(row, chunk_size, overlap):\n",
    "    start_index = row[\"chunk\"].metadata[\"start_index\"]\n",
    "    text_length = len(row[\"text\"])\n",
    "\n",
    "    if start_index - overlap < 0:\n",
    "        return row[\"text\"][start_index : start_index + chunk_size + overlap]\n",
    "    if start_index + chunk_size + overlap > text_length:\n",
    "        return row[\"text\"][start_index - overlap : text_length]\n",
    "\n",
    "    return row[\"text\"][start_index - overlap : start_index + chunk_size + overlap]\n",
    "\n",
    "\n",
    "def get_context(db: pd.DataFrame, chunk_size, overlap: int = 100) -> pd.DataFrame:\n",
    "    # Apply the function to each row of the DataFrame\n",
    "    db[\"context\"] = db.apply(\n",
    "        get_context_for_row, chunk_size=chunk_size, overlap=overlap, axis=1\n",
    "    )\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_chunks(db: pd.DataFrame, text_splitter) -> pd.DataFrame:\n",
    "    db[\"chunk\"] = db[\"text\"].apply(lambda s: text_splitter.create_documents([s]))\n",
    "    return db.explode(\"chunk\")\n",
    "\n",
    "\n",
    "def get_embeddings(db: pd.DataFrame, model) -> pd.DataFrame:\n",
    "    db[\"embedding\"] = db[\"chunk\"].apply(lambda s: model.encode(s.page_content))\n",
    "    return db\n",
    "\n",
    "\n",
    "def separate_tables(db):\n",
    "    return db[[\"file_name\", \"file_path\", \"text\"]].drop_duplicates(\n",
    "        subset=\"file_name\"\n",
    "    ), db.drop(columns=['file_path', 'text'])\n",
    "\n",
    "\n",
    "def to_postgres():\n",
    "    NotImplemented\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "db = get_files(os.getcwd() + \"\\data\\\\\")\n",
    "db = get_text(db)\n",
    "db = get_chunks(db, text_splitter)\n",
    "db = get_context(db, CHUNK_SIZE)\n",
    "db = get_embeddings(db, model)\n",
    "text_db, vector_db = separate_tables(db)\n",
    "#to_postgres(db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legislation-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
